{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Networks\n",
    "\n",
    "We'll check out how to build a **convolutional network** to classify CIFAR10 images. By using weight sharing - multiple units with the same weights - convolutional layers are able to learn repeated patterns in your data. For example, a unit could learn the pattern for an eye, or a face, or lower level features like edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchsummary import summary  # install with 'pip install torchsummary'\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from models import ConvNet\n",
    "from utils import plot_images, get_train_valid_loader, plot_weights, plot_gradient_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loaders\n",
    "trainloader, valloader = get_train_valid_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init net\n",
    "net = ConvNet()\n",
    "\n",
    "# plot net parameters\n",
    "summary(net, input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize init weights\n",
    "w = net.conv1.weight.data.numpy()\n",
    "plot_weights(w,scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "learning_rate = 1e-2\n",
    "decayRate = 0.2\n",
    "l2_reg = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "\n",
    "# https://discuss.pytorch.org/t/how-to-do-exponential-learning-rate-decay-in-pytorch/63146/3\n",
    "# https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=decayRate, patience=3, threshold=1e-2, verbose = True)\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "running_loss = 0\n",
    "print_every = 200\n",
    "training_steps = 0\n",
    "\n",
    "# init tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "val_acc_best = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    print('\\n--- EPOCH %03d / %03d STARTED ---' % (e+1, epochs))\n",
    " \n",
    "    # set net to train mode\n",
    "    net.train()\n",
    "    \n",
    "    # log current learning rate\n",
    "    writer.add_scalar('optimizer/learning_rate', optimizer.param_groups[0]['lr'], e+1)\n",
    "    \n",
    "    # train over all batches\n",
    "    start = time.time()\n",
    "    for idx_batch, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        training_steps += 1\n",
    "        \n",
    "        if idx_batch % print_every == 0:\n",
    "            print('---> train on batch %03d' % idx_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        plot_gradient_flow(net.named_parameters())\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('train/loss_training_step', loss.item(), training_steps)\n",
    "        \n",
    "    # set net to evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # evaluate on training data \n",
    "    train_loss_accum = 0.\n",
    "    count_total = 0\n",
    "    count_correct = 0\n",
    "    for idx_batch, (images, labels) in enumerate(trainloader):\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        train_loss_accum += loss.item()\n",
    "        \n",
    "        prediction = torch.argmax(F.softmax(output), axis=1)\n",
    "        count_total += prediction.size(0)\n",
    "        count_correct += (prediction == labels).sum().item()\n",
    "        \n",
    "    train_loss_avg = train_loss_accum / (idx_batch+1)\n",
    "    train_acc = count_correct / count_total\n",
    "    writer.add_scalar('train/loss_epoch', train_loss_avg, e+1)\n",
    "    writer.add_scalar('train/accuracy', train_acc, e+1)\n",
    "    \n",
    "    # evaluate on validation data \n",
    "    val_loss_accum = 0.\n",
    "    count_total = 0\n",
    "    count_correct = 0\n",
    "    for idx_batch, (images, labels) in enumerate(valloader):\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        val_loss_accum += loss.item()\n",
    "        \n",
    "        prediction = torch.argmax(F.softmax(output), axis=1)\n",
    "        count_total += prediction.size(0)\n",
    "        count_correct += (prediction == labels).sum().item()\n",
    "\n",
    "    val_loss_avg = val_loss_accum / (idx_batch+1)\n",
    "    val_acc = count_correct / count_total\n",
    "    writer.add_scalar('val/loss_epoch', val_loss_avg, e+1)\n",
    "    writer.add_scalar('val/accuracy', val_acc, e+1)\n",
    "    \n",
    "    print('\\nMetrics: ')\n",
    "    print('---> train loss / accuracy: %.03f / %.03f' % (train_loss_avg, train_acc))\n",
    "    print('---> val loss / accuracy:   %.03f / %.03f' % (val_loss_avg, val_acc))\n",
    "    \n",
    "    scheduler.step(val_loss_avg)\n",
    "    \n",
    "    # print('filters conv1')\n",
    "    # w1 = net.conv1.weight.data.numpy()\n",
    "    # plot_weights(w1, scaling=True)\n",
    "    # plt.show()\n",
    "    \n",
    "    if val_acc > val_acc_best:\n",
    "        val_acc_best = val_acc\n",
    "        print('---> save new best checkpoint')\n",
    "        torch.save(net.state_dict(), 'model_%.03f.ckpt' % val_acc)\n",
    "\n",
    "# close tensorboard logging\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save best trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
