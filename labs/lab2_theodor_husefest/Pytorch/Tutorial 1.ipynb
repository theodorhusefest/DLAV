{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning with PyTorch\n",
    "\n",
    "In this notebook, you'll get introduced to [PyTorch](http://pytorch.org/), a framework for building and training neural networks. PyTorch in a lot of ways behaves like the arrays you love from Numpy. These Numpy arrays, after all, are just tensors. PyTorch takes these tensors and makes it simple to move them to GPUs for the faster processing needed when training neural networks. It also provides a module that automatically calculates gradients (for backpropagation!) and another module specifically for building neural networks. All together, PyTorch ends up being more coherent with Python and the Numpy/Scipy stack compared to TensorFlow and other frameworks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Deep Learning is based on artificial neural networks which have been around in some form since the late 1950s. The networks are built from individual parts approximating neurons, typically called units or simply \"neurons.\" Each unit has some number of weighted inputs. These weighted inputs are summed together (a linear combination) then passed through an activation function to get the unit's output.\n",
    "\n",
    "<img src=\"assets/simple_neuron.png\" width=400px>\n",
    "\n",
    "Mathematically this looks like: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "y &= f\\left(\\sum_i w_i x_i \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With vectors this is the dot/inner product of two vectors:\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots  x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_1 \\\\\n",
    "           w_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           w_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack them up!\n",
    "\n",
    "We can assemble these unit neurons into layers and stacks, into a network of neurons. The output of one layer of neurons becomes the input for the next layer. With multiple input units and output units, we now need to express the weights as a matrix.\n",
    "\n",
    "<img src='assets/multilayer_diagram_weights.png' width=450px>\n",
    "\n",
    "We can express this mathematically with matrices again and use matrix multiplication to get linear combinations for each unit in one operation. For example, the hidden layer ($h_1$ and $h_2$ here) can be calculated \n",
    "\n",
    "$$\n",
    "\\vec{h} = [h_1 \\, h_2] = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots \\, x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_{11} & w_{12} \\\\\n",
    "           w_{21} &w_{22} \\\\\n",
    "           \\vdots &\\vdots \\\\\n",
    "           w_{n1} &w_{n2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The output for this small network is found by treating the hidden layer as inputs for the output unit. The network output is expressed simply\n",
    "\n",
    "$$\n",
    "y =  f_2 \\! \\left(\\, f_1 \\! \\left(\\vec{x} \\, \\mathbf{W_1}\\right) \\mathbf{W_2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "It turns out neural network computations are just a bunch of linear algebra operations on *tensors*, a generalization of matrices. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, an array with three indices is a 3-dimensional tensor (RGB color images for example). The fundamental data structure for neural networks are tensors and PyTorch (as well as pretty much every other deep learning framework) is built around tensors.\n",
    "\n",
    "<img src=\"assets/tensor_examples.svg\" width=600px>\n",
    "\n",
    "With the basics covered, it's time to explore how we can use PyTorch to build a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see how we work with PyTorch tensors. These are the fundamental data structures of neural networks and PyTorch, so it's imporatant to understand how these work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3679, 0.7718],\n",
       "        [0.0270, 0.7105],\n",
       "        [0.3206, 0.5374]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(x.size())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3679, 1.7718],\n",
       "        [1.0270, 1.7105],\n",
       "        [1.3206, 1.5374]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general PyTorch tensors behave similar to Numpy arrays. They are zero indexed and support slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3679, 1.7718])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7718],\n",
       "        [1.7105],\n",
       "        [1.5374]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors typically have two forms of methods, one method that returns another tensor and another method that performs the operation in place. That is, the values in memory for that tensor are changed without creating a new tensor. In-place functions are always followed by an underscore, for example `z.add()` and `z.add_()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3679, 2.7718],\n",
       "        [2.0270, 2.7105],\n",
       "        [2.3206, 2.5374]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a new tensor z + 1\n",
    "z.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3679, 1.7718],\n",
       "        [1.0270, 1.7105],\n",
       "        [1.3206, 1.5374]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z tensor is unchanged\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3679, 2.7718],\n",
       "        [2.0270, 2.7105],\n",
       "        [2.3206, 2.5374]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 1 and update z tensor in-place\n",
    "z.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3679, 2.7718],\n",
       "        [2.0270, 2.7105],\n",
       "        [2.3206, 2.5374]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z has been updated\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping\n",
    "\n",
    "Reshaping tensors is a really common operation. First to get the size and shape of a tensor use `.size()`. Then, to reshape a tensor, use `.resize_()`. Notice the underscore, reshaping is an in-place operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3679, 2.7718, 2.0270],\n",
       "        [2.7105, 2.3206, 2.5374]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.resize_(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3679, 2.7718, 2.0270],\n",
       "        [2.7105, 2.3206, 2.5374]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy to Torch and back\n",
    "\n",
    "Converting between Numpy arrays and Torch tensors is super simple and useful. To create a tensor from a Numpy array, use `torch.from_numpy()`. To convert a tensor to a Numpy array, use the `.numpy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64759104, 0.44178697, 0.64358274],\n",
       "       [0.01031438, 0.68770473, 0.05951144],\n",
       "       [0.33061222, 0.56331237, 0.4579029 ],\n",
       "       [0.45505682, 0.05777277, 0.39140311]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6476, 0.4418, 0.6436],\n",
       "        [0.0103, 0.6877, 0.0595],\n",
       "        [0.3306, 0.5633, 0.4579],\n",
       "        [0.4551, 0.0578, 0.3914]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64759104, 0.44178697, 0.64358274],\n",
       "       [0.01031438, 0.68770473, 0.05951144],\n",
       "       [0.33061222, 0.56331237, 0.4579029 ],\n",
       "       [0.45505682, 0.05777277, 0.39140311]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2952, 0.8836, 1.2872],\n",
       "        [0.0206, 1.3754, 0.1190],\n",
       "        [0.6612, 1.1266, 0.9158],\n",
       "        [0.9101, 0.1155, 0.7828]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply PyTorch Tensor by 2, in place\n",
    "b.mul_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.29518208, 0.88357394, 1.28716547],\n",
       "       [0.02062876, 1.37540946, 0.11902287],\n",
       "       [0.66122444, 1.12662473, 0.91580581],\n",
       "       [0.91011364, 0.11554553, 0.78280623]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array matches new values from Tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward neural networks with PyTorch\n",
    "\n",
    "Next I'll show you how to use this pattern to build a neural network with PyTorch. First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                             ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x126decf90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
    "\n",
    "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 128, 64, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ''' This function for predicts classes by calculating the softmax '''\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)\n",
    "\n",
    "net = Network()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `net.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.fc1.weight)\n",
    "print(net.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom initialization, we want to modify these tensors in place. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set biases to all zeros\n",
    "net.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "net.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "inputs, labels = dataiter.next()\n",
    "inputs.resize_(64, 1, 784)\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "logits = net(inputs[img_idx,:])\n",
    "\n",
    "# Predict the class from the network output\n",
    "ps = F.softmax(logits)\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random! Next up, we'll look at training this network so it learns how to properly classify these digits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
